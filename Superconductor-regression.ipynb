{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c14d776b",
   "metadata": {},
   "source": [
    "The aim of this analysis is to predit a superconductors critical temperature based on the variables from the superconductors chemical formula. We will be training a few different predictive models and compare them to find the best one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8aa87d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import sklearn.model_selection as ms\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcd01c93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number_of_elements</th>\n",
       "      <th>mean_atomic_mass</th>\n",
       "      <th>wtd_mean_atomic_mass</th>\n",
       "      <th>gmean_atomic_mass</th>\n",
       "      <th>wtd_gmean_atomic_mass</th>\n",
       "      <th>entropy_atomic_mass</th>\n",
       "      <th>wtd_entropy_atomic_mass</th>\n",
       "      <th>range_atomic_mass</th>\n",
       "      <th>wtd_range_atomic_mass</th>\n",
       "      <th>std_atomic_mass</th>\n",
       "      <th>...</th>\n",
       "      <th>wtd_mean_Valence</th>\n",
       "      <th>gmean_Valence</th>\n",
       "      <th>wtd_gmean_Valence</th>\n",
       "      <th>entropy_Valence</th>\n",
       "      <th>wtd_entropy_Valence</th>\n",
       "      <th>range_Valence</th>\n",
       "      <th>wtd_range_Valence</th>\n",
       "      <th>std_Valence</th>\n",
       "      <th>wtd_std_Valence</th>\n",
       "      <th>critical_temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>88.944468</td>\n",
       "      <td>57.862692</td>\n",
       "      <td>66.361592</td>\n",
       "      <td>36.116612</td>\n",
       "      <td>1.181795</td>\n",
       "      <td>1.062396</td>\n",
       "      <td>122.90607</td>\n",
       "      <td>31.794921</td>\n",
       "      <td>51.968828</td>\n",
       "      <td>...</td>\n",
       "      <td>2.257143</td>\n",
       "      <td>2.213364</td>\n",
       "      <td>2.219783</td>\n",
       "      <td>1.368922</td>\n",
       "      <td>1.066221</td>\n",
       "      <td>1</td>\n",
       "      <td>1.085714</td>\n",
       "      <td>0.433013</td>\n",
       "      <td>0.437059</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>92.729214</td>\n",
       "      <td>58.518416</td>\n",
       "      <td>73.132787</td>\n",
       "      <td>36.396602</td>\n",
       "      <td>1.449309</td>\n",
       "      <td>1.057755</td>\n",
       "      <td>122.90607</td>\n",
       "      <td>36.161939</td>\n",
       "      <td>47.094633</td>\n",
       "      <td>...</td>\n",
       "      <td>2.257143</td>\n",
       "      <td>1.888175</td>\n",
       "      <td>2.210679</td>\n",
       "      <td>1.557113</td>\n",
       "      <td>1.047221</td>\n",
       "      <td>2</td>\n",
       "      <td>1.128571</td>\n",
       "      <td>0.632456</td>\n",
       "      <td>0.468606</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>88.944468</td>\n",
       "      <td>57.885242</td>\n",
       "      <td>66.361592</td>\n",
       "      <td>36.122509</td>\n",
       "      <td>1.181795</td>\n",
       "      <td>0.975980</td>\n",
       "      <td>122.90607</td>\n",
       "      <td>35.741099</td>\n",
       "      <td>51.968828</td>\n",
       "      <td>...</td>\n",
       "      <td>2.271429</td>\n",
       "      <td>2.213364</td>\n",
       "      <td>2.232679</td>\n",
       "      <td>1.368922</td>\n",
       "      <td>1.029175</td>\n",
       "      <td>1</td>\n",
       "      <td>1.114286</td>\n",
       "      <td>0.433013</td>\n",
       "      <td>0.444697</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>88.944468</td>\n",
       "      <td>57.873967</td>\n",
       "      <td>66.361592</td>\n",
       "      <td>36.119560</td>\n",
       "      <td>1.181795</td>\n",
       "      <td>1.022291</td>\n",
       "      <td>122.90607</td>\n",
       "      <td>33.768010</td>\n",
       "      <td>51.968828</td>\n",
       "      <td>...</td>\n",
       "      <td>2.264286</td>\n",
       "      <td>2.213364</td>\n",
       "      <td>2.226222</td>\n",
       "      <td>1.368922</td>\n",
       "      <td>1.048834</td>\n",
       "      <td>1</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>0.433013</td>\n",
       "      <td>0.440952</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>88.944468</td>\n",
       "      <td>57.840143</td>\n",
       "      <td>66.361592</td>\n",
       "      <td>36.110716</td>\n",
       "      <td>1.181795</td>\n",
       "      <td>1.129224</td>\n",
       "      <td>122.90607</td>\n",
       "      <td>27.848743</td>\n",
       "      <td>51.968828</td>\n",
       "      <td>...</td>\n",
       "      <td>2.242857</td>\n",
       "      <td>2.213364</td>\n",
       "      <td>2.206963</td>\n",
       "      <td>1.368922</td>\n",
       "      <td>1.096052</td>\n",
       "      <td>1</td>\n",
       "      <td>1.057143</td>\n",
       "      <td>0.433013</td>\n",
       "      <td>0.428809</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   number_of_elements  mean_atomic_mass  wtd_mean_atomic_mass  \\\n",
       "0                   4         88.944468             57.862692   \n",
       "1                   5         92.729214             58.518416   \n",
       "2                   4         88.944468             57.885242   \n",
       "3                   4         88.944468             57.873967   \n",
       "4                   4         88.944468             57.840143   \n",
       "\n",
       "   gmean_atomic_mass  wtd_gmean_atomic_mass  entropy_atomic_mass  \\\n",
       "0          66.361592              36.116612             1.181795   \n",
       "1          73.132787              36.396602             1.449309   \n",
       "2          66.361592              36.122509             1.181795   \n",
       "3          66.361592              36.119560             1.181795   \n",
       "4          66.361592              36.110716             1.181795   \n",
       "\n",
       "   wtd_entropy_atomic_mass  range_atomic_mass  wtd_range_atomic_mass  \\\n",
       "0                 1.062396          122.90607              31.794921   \n",
       "1                 1.057755          122.90607              36.161939   \n",
       "2                 0.975980          122.90607              35.741099   \n",
       "3                 1.022291          122.90607              33.768010   \n",
       "4                 1.129224          122.90607              27.848743   \n",
       "\n",
       "   std_atomic_mass  ...  wtd_mean_Valence  gmean_Valence  wtd_gmean_Valence  \\\n",
       "0        51.968828  ...          2.257143       2.213364           2.219783   \n",
       "1        47.094633  ...          2.257143       1.888175           2.210679   \n",
       "2        51.968828  ...          2.271429       2.213364           2.232679   \n",
       "3        51.968828  ...          2.264286       2.213364           2.226222   \n",
       "4        51.968828  ...          2.242857       2.213364           2.206963   \n",
       "\n",
       "   entropy_Valence  wtd_entropy_Valence  range_Valence  wtd_range_Valence  \\\n",
       "0         1.368922             1.066221              1           1.085714   \n",
       "1         1.557113             1.047221              2           1.128571   \n",
       "2         1.368922             1.029175              1           1.114286   \n",
       "3         1.368922             1.048834              1           1.100000   \n",
       "4         1.368922             1.096052              1           1.057143   \n",
       "\n",
       "   std_Valence  wtd_std_Valence  critical_temp  \n",
       "0     0.433013         0.437059           29.0  \n",
       "1     0.632456         0.468606           26.0  \n",
       "2     0.433013         0.444697           19.0  \n",
       "3     0.433013         0.440952           22.0  \n",
       "4     0.433013         0.428809           23.0  \n",
       "\n",
       "[5 rows x 82 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conductivity = pd.read_csv(\"data/train.csv\", header=0, na_values='?').dropna()\n",
    "conductivity.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fec1e99d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame datatypes :\n",
      " number_of_elements         int64\n",
      "mean_atomic_mass         float64\n",
      "wtd_mean_atomic_mass     float64\n",
      "gmean_atomic_mass        float64\n",
      "wtd_gmean_atomic_mass    float64\n",
      "                          ...   \n",
      "range_Valence              int64\n",
      "wtd_range_Valence        float64\n",
      "std_Valence              float64\n",
      "wtd_std_Valence          float64\n",
      "critical_temp            float64\n",
      "Length: 82, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print('\\nDataFrame datatypes :\\n', conductivity.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2a7510",
   "metadata": {},
   "source": [
    "Splitting our dataset into predictor and response vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca139638",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = conductivity.drop(['critical_temp'], axis=1) # X variable is the dataset without the class column\n",
    "X = X.values \n",
    "Y = conductivity.iloc[:,81:82].values # Y variable is only the critical temp column\n",
    "# the 81:82 is important, because otherwise it returns just a 1-dimensional object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0beb5d",
   "metadata": {},
   "source": [
    "Now, because we are using LASSO and Ridge regression, we need to standardize our predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "608e989a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing the predictors\n",
    "X_mean = np.reshape(X.mean(0), (-1,81))\n",
    "X_std = np.reshape(X.std(0), (-1,81))\n",
    "X_stand = (X - X_mean) / X_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9079787f",
   "metadata": {},
   "source": [
    "Finally, we split our data into training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e3049c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.model_selection as cv \n",
    "XTrain, XTest, YTrain, Ytest =\\\n",
    "    cv.train_test_split(X_stand, Y, \\\n",
    "    test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4619f4",
   "metadata": {},
   "source": [
    "Now we must tune our hyperparameters for the LASSO and Ridge regression. To do this, we utilize a grid search. The intervals I have chosen were found through trial and error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be61b721",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "lambda_ridge_range = np.linspace(0.001,0.2,50) \n",
    "lambda_ridge_grid = [{'alpha': lambda_ridge_range}]\n",
    "lambda_lasso_range = np.linspace(0.0001,0.002, 20)\n",
    "lambda_lasso_grid = [{'alpha': lambda_lasso_range}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262292b1",
   "metadata": {},
   "source": [
    "We now utilize k-fold cross validation, where k=11. k=10 is usual, but it can also help to have your choice of k evenly divide your sample size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bcad909e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=11, random_state=None, shuffle=False),\n",
       "             estimator=Ridge(max_iter=10000),\n",
       "             param_grid=[{'alpha': array([0.001     , 0.00506122, 0.00912245, 0.01318367, 0.0172449 ,\n",
       "       0.02130612, 0.02536735, 0.02942857, 0.0334898 , 0.03755102,\n",
       "       0.04161224, 0.04567347, 0.04973469, 0.05379592, 0.05785714,\n",
       "       0.06191837, 0.06597959, 0.07004082, 0.07410204, 0.07816327,\n",
       "       0.08222449, 0.08628571, 0.09034694, 0.09440816, 0.09846939,\n",
       "       0.10253061, 0.10659184, 0.11065306, 0.11471429, 0.11877551,\n",
       "       0.12283673, 0.12689796, 0.13095918, 0.13502041, 0.13908163,\n",
       "       0.14314286, 0.14720408, 0.15126531, 0.15532653, 0.15938776,\n",
       "       0.16344898, 0.1675102 , 0.17157143, 0.17563265, 0.17969388,\n",
       "       0.1837551 , 0.18781633, 0.19187755, 0.19593878, 0.2       ])}])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = Ridge(max_iter=10000)\n",
    "cv_ridge = GridSearchCV(estimator=model1,\\\n",
    "param_grid=lambda_ridge_grid,\\\n",
    "cv=ms.KFold(n_splits=11))\n",
    "cv_ridge.fit(XTrain, YTrain) # alpha = 0.04973469"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab8aad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Lasso(max_iter=100000) # I had to put max iter up so high because\n",
    "                              # otherwise the Lasso was not converging.\n",
    "cv_lasso = GridSearchCV(estimator=model2,\\\n",
    "param_grid=lambda_lasso_grid,\\\n",
    "cv=ms.KFold(n_splits=11))\n",
    "cv_lasso.fit(XTrain, YTrain) # alpha = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b0d6af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bestLambda_lasso = 0.0001\n",
    "bestLambda_ridge = 0.04973469"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67266ff6",
   "metadata": {},
   "source": [
    "Now we train our regressions using the optimized hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1bf03019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5.42614935e+00  2.57676996e+01 -3.18817524e+01 -1.58224736e+01\n",
      "  2.44125467e+01 -1.35644627e+01  1.37391829e+00  1.15706924e+01\n",
      "  1.18374158e+00 -1.11080166e+01  1.61983456e+00  1.62098435e+01\n",
      " -3.33588572e+01 -1.39471559e+01  3.01325279e+01 -4.75837114e+01\n",
      "  1.44791745e+01  2.22297681e+01  4.82692248e+00 -2.33424806e+01\n",
      " -1.46066432e+00 -1.29737382e+01  1.00318661e+02  6.28765435e+00\n",
      " -1.09695328e+02  3.18971796e+01  1.88185334e+01  1.31630092e+01\n",
      " -3.45528179e+00 -7.37285636e+00 -9.93333705e+00 -1.43394893e+01\n",
      "  1.94801679e-01  5.50318796e+00  8.41269498e+00  5.42871974e+00\n",
      " -6.68416526e+00 -5.79242221e+00 -4.01920545e-01  9.44998084e+00\n",
      " -2.24237546e+00 -2.37453217e+00  1.62997574e+01  4.76481059e+00\n",
      " -1.77200013e+01  1.26112704e+00 -6.07922045e+00 -2.20162530e+01\n",
      " -4.11866575e+00  2.70824560e+01 -1.09352977e+01  2.02310463e+01\n",
      " -2.77986129e+01 -1.62928267e+01  2.14765810e+01 -6.96861414e+00\n",
      "  9.37790419e+00 -8.60077318e+00  6.91269476e+00 -4.30187748e+00\n",
      "  5.71085603e+00 -2.22577738e+00  2.30687937e+01 -2.51270192e+00\n",
      " -1.21650674e+01  3.66879462e+00  3.50674111e-01 -1.36594316e+01\n",
      " -9.87692614e+00  1.65663205e+01 -8.53539818e-02 -1.60971567e+01\n",
      "  2.80747404e+01  2.03271987e+01 -3.23434622e+01  3.01646534e+01\n",
      " -2.60872611e+01  6.72638889e+00 -6.73408989e-01  2.66705325e+00\n",
      " -1.14534800e+01]\n",
      "[[-5.45261480e+00  2.58421488e+01 -3.19414279e+01 -1.58982461e+01\n",
      "   2.44775002e+01 -1.35846509e+01  1.41848537e+00  1.15898438e+01\n",
      "   1.19624577e+00 -1.11589557e+01  1.64498936e+00  1.62513612e+01\n",
      "  -3.28228377e+01 -1.39767660e+01  2.96736655e+01 -4.70322365e+01\n",
      "   1.44153091e+01  2.22599524e+01  4.81834895e+00 -2.33615733e+01\n",
      "  -1.50640076e+00 -1.25677891e+01  9.91232689e+01  5.86951794e+00\n",
      "  -1.08247923e+02  3.15714991e+01  1.87297161e+01  1.32255764e+01\n",
      "  -3.44587968e+00 -7.65992255e+00 -9.58615010e+00 -1.43962289e+01\n",
      "   3.09405133e-01  5.54919544e+00  8.30141021e+00  5.47026609e+00\n",
      "  -6.70129913e+00 -5.81070800e+00 -4.21135098e-01  9.50161039e+00\n",
      "  -2.27408469e+00 -2.42592546e+00  1.63937018e+01  4.81099097e+00\n",
      "  -1.78028967e+01  1.25474078e+00 -6.07133742e+00 -2.20334723e+01\n",
      "  -4.12645111e+00  2.71148406e+01 -1.09592607e+01  2.02917193e+01\n",
      "  -2.78948562e+01 -1.63298825e+01  2.15439156e+01 -6.97978165e+00\n",
      "   9.39071393e+00 -8.59431816e+00  6.92161491e+00 -4.35450147e+00\n",
      "   5.75618650e+00 -2.22700620e+00  2.30679468e+01 -2.51636590e+00\n",
      "  -1.21567563e+01  3.66956429e+00  3.46966120e-01 -1.36785345e+01\n",
      "  -9.88053066e+00  1.65931632e+01 -8.87900242e-02 -1.65408635e+01\n",
      "   2.85749111e+01  2.07392998e+01 -3.27954708e+01  2.99590143e+01\n",
      "  -2.59943525e+01  6.71496551e+00 -6.71148485e-01  2.71998100e+00\n",
      "  -1.15034362e+01]]\n"
     ]
    }
   ],
   "source": [
    "cond_Lasso = Lasso(alpha=bestLambda_lasso,max_iter=100000)\n",
    "cond_Lasso.fit(XTrain, YTrain)\n",
    "print(cond_Lasso.coef_)\n",
    "\n",
    "cond_Ridge = Ridge(alpha=bestLambda_ridge,max_iter=10000)\n",
    "cond_Ridge.fit(XTrain, YTrain)\n",
    "print(cond_Ridge.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37ba7f3",
   "metadata": {},
   "source": [
    "We can look at the differences between the coefficients of each variable from each model to see how different each model is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "712438b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.64654470e-02 -7.44491710e-02  5.96755402e-02  7.57724525e-02\n",
      "  -6.49535480e-02  2.01881609e-02 -4.45670842e-02 -1.91513809e-02\n",
      "  -1.25041946e-02  5.09390448e-02 -2.51547996e-02 -4.15176958e-02\n",
      "  -5.36019477e-01  2.96101609e-02  4.58862385e-01 -5.51474925e-01\n",
      "   6.38654460e-02 -3.01842917e-02  8.57353293e-03  1.90926962e-02\n",
      "   4.57364396e-02 -4.05949174e-01  1.19539218e+00  4.18136405e-01\n",
      "  -1.44740523e+00  3.25680539e-01  8.88173285e-02 -6.25671847e-02\n",
      "  -9.40210731e-03  2.87066196e-01 -3.47186951e-01  5.67395900e-02\n",
      "  -1.14603455e-01 -4.60074762e-02  1.11284772e-01 -4.15463434e-02\n",
      "   1.71338688e-02  1.82857947e-02  1.92145529e-02 -5.16295522e-02\n",
      "   3.17092262e-02  5.13932875e-02 -9.39444913e-02 -4.61803806e-02\n",
      "   8.28953326e-02  6.38625922e-03 -7.88302271e-03  1.72192828e-02\n",
      "   7.78536902e-03 -3.23846364e-02  2.39629715e-02 -6.06730439e-02\n",
      "   9.62432707e-02  3.70557708e-02 -6.73346101e-02  1.11675154e-02\n",
      "  -1.28097451e-02 -6.45502792e-03 -8.92014979e-03  5.26239841e-02\n",
      "  -4.53304697e-02  1.22881943e-03  8.46967778e-04  3.66397833e-03\n",
      "  -8.31106346e-03 -7.69671865e-04  3.70799105e-03  1.91028891e-02\n",
      "   3.60452097e-03 -2.68427016e-02  3.43604240e-03  4.43706726e-01\n",
      "  -5.00170702e-01 -4.12101073e-01  4.52008572e-01  2.05639153e-01\n",
      "  -9.29086720e-02  1.14233787e-02 -2.26050345e-03 -5.29277430e-02\n",
      "   4.99561373e-02]]\n"
     ]
    }
   ],
   "source": [
    "print(cond_Lasso.coef_ - cond_Ridge.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ac7a67",
   "metadata": {},
   "source": [
    "The coefficients are very similar. Most are the same out to 2 decimal places."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c085e6a",
   "metadata": {},
   "source": [
    "Do some quick reshaping to get 2d vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02dcfd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_train_prediction = np.reshape(cond_Lasso.predict(XTrain), (-1,17010))\n",
    "lasso_test_prediction = np.reshape(cond_Lasso.predict(XTest), (-1, 4253))\n",
    "ridge_train_prediction = np.reshape(cond_Ridge.predict(XTrain), (-1, 17010))\n",
    "ridge_test_prediction = np.reshape(cond_Ridge.predict(XTest), (-1, 4253))\n",
    "\n",
    "Lasso_MSEtrain = metrics.mean_squared_error(YTrain, lasso_train_prediction.T)\n",
    "Lasso_MSEtest = metrics.mean_squared_error(Ytest, lasso_test_prediction.T)\n",
    "Ridge_MSEtrain = metrics.mean_squared_error(YTrain, ridge_train_prediction.T)\n",
    "Ridge_MSEtest = metrics.mean_squared_error(Ytest, ridge_test_prediction.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb4ea7e",
   "metadata": {},
   "source": [
    "We have the first two models trained, now we move on to the Principal Component and Partial Least Squares Regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f3d57ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import decomposition\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab9cd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "condPCA = decomposition.PCA()\n",
    "cond_Decomp = condPCA.fit(XTrain)\n",
    "X_decomp = cond_Decomp.transform(XTrain)\n",
    "var_ratio = condPCA.explained_variance_ratio_\n",
    "np.cumsum(np.round(var_ratio, decimals=4)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584d1e4f",
   "metadata": {},
   "source": [
    "We can see above that 12 principal components gets us to ~90% of variance explained, so we use 12 principal components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "767f3bf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'explained variance')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_components = 12\n",
    "pca = TruncatedSVD(n_components=n_components)\n",
    "X_train_pca = pca.fit_transform(XTrain)\n",
    "X_test_pca = pca.fit_transform(XTest)\n",
    "\n",
    "components = pca.components_\n",
    "plt.plot(pca.explained_variance_)\n",
    "plt.xlabel('component')\n",
    "plt.ylabel('explained variance')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afe55de",
   "metadata": {},
   "source": [
    "Our principal components analysis is done, so we now do regression on the principal components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cd673673",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6117deca",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcr = LinearRegression()\n",
    "pcr.fit(X_train_pca, YTrain)\n",
    "pcr_MSEtrain = metrics.mean_squared_error(YTrain,pcr.predict(X_train_pca))\n",
    "pcr_MSEtest = metrics.mean_squared_error(Ytest, pcr.predict(X_test_pca))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c6b233",
   "metadata": {},
   "source": [
    "And now we train the partial least squares regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bf124c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2868d3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pls = PLSRegression(n_components=n_components)\n",
    "pls.fit(scale(XTrain), YTrain)\n",
    "pls_MSEtrain = metrics.mean_squared_error(YTrain,pls.predict(scale(XTrain)))\n",
    "pls_MSEtest = metrics.mean_squared_error(Ytest,pls.predict(scale(XTest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdc5599",
   "metadata": {},
   "source": [
    "To finish off the models, we do an ordinary least squares regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f5f86b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "OLS = LinearRegression()\n",
    "OLS.fit(XTrain, YTrain)\n",
    "OLS_MSEtrain = metrics.mean_squared_error(YTrain, OLS.predict(XTrain))\n",
    "OLS_MSEtest = metrics.mean_squared_error(Ytest, OLS.predict(XTest))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687aca4f",
   "metadata": {},
   "source": [
    "Do some simple print commands to compare training and testing errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "974b8879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The OLS training error is 306.0759047713742  and the OLS testing error is 318.2777505906926\n",
      "The Ridge training error is 306.0797094248285  and the Ridge testing error is 318.18710645738366\n",
      "The Lasso training error is 306.07862958529387  and the Lasso testing error is 318.21233505812893\n",
      "The PCR training error is 484.3618201577728  and the PCR testing error is 864.3148801839544\n",
      "The PLS training error is 346.96005275106666  and the PLS testing error is 348.75312980339515\n"
     ]
    }
   ],
   "source": [
    "print('The OLS training error is', OLS_MSEtrain, ' and the OLS testing error is', OLS_MSEtest)\n",
    "print('The Ridge training error is', Ridge_MSEtrain, ' and the Ridge testing error is', Ridge_MSEtest)\n",
    "print('The Lasso training error is', Lasso_MSEtrain, ' and the Lasso testing error is', Lasso_MSEtest)\n",
    "print('The PCR training error is', pcr_MSEtrain, ' and the PCR testing error is', pcr_MSEtest)\n",
    "print('The PLS training error is', pls_MSEtrain, ' and the PLS testing error is', pls_MSEtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400ba5a8",
   "metadata": {},
   "source": [
    "The testing and training errors for three of these are very close. It is obvious that PCR and PLS are not the best models for the data. It comes down to OLS, Ridge and Lasso regressions. I think it is safe to say that any three of these would work almost equally as well as the others, but Lasso has the smallest testing error and it stands to be improved the most by finding a more accurate alpha value, so I believe the Lasso regression is the best model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
